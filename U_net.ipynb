{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1F57esqTWFWdvRDZvg4jaUDa4_Rk_paUw",
      "authorship_tag": "ABX9TyNtjo5dwdpD0ItbsRAzVzqV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/woojung02/SSAC_AI/blob/main/U_net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1 임포트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "#2.RLE  이미지로 복원하는 과정\n",
        "def rle2mask(rle, shape):\n",
        "    \"\"\"\n",
        "    RLE 문자열 → 2D 이진 마스크\n",
        "    shape = (height, width)\n",
        "    \"\"\"\n",
        "    h, w = shape\n",
        "    mask = np.zeros(h * w, dtype=np.uint8)\n",
        "    if isinstance(rle, str):\n",
        "        vals = np.array(rle.split(), dtype=int)\n",
        "        starts, lengths = vals[0::2] - 1, vals[1::2]\n",
        "        for s, l in zip(starts, lengths):\n",
        "            mask[s : s + l] = 1\n",
        "    return mask.reshape((h, w), order='F')\n",
        "\n",
        "#3. 데이터 로드및 전처리\n",
        "CSV_PATH   = \"/content/train.csv\"\n",
        "IMG_FOLDER = \"/content/drive/MyDrive/train_images\"\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "# Mask 없는(EncodedPixels NaN) 행 제거\n",
        "df = df[df['EncodedPixels'].notnull()].reset_index(drop=True)\n",
        "\n",
        "# 존재하지 않는 파일 필터링\n",
        "exists = df['ImageId'].apply(lambda fn: os.path.exists(os.path.join(IMG_FOLDER, fn)))\n",
        "df = df[exists].reset_index(drop=True)\n",
        "print(f\"총 샘플 수: {len(df)}\")\n",
        "\n",
        "\n",
        "# 4) Dataset 정의\n",
        "\n",
        "class SteelDataset(Dataset):\n",
        "    def __init__(self, df, img_dir, transform=None):\n",
        "        self.df = df\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fn  = self.df.loc[idx, \"ImageId\"]\n",
        "        rle = self.df.loc[idx, \"EncodedPixels\"]\n",
        "        # 이미지 로드\n",
        "        img = Image.open(os.path.join(self.img_dir, fn)).convert(\"RGB\")\n",
        "        # 마스크 생성\n",
        "        mask = rle2mask(rle, (256, 1600))\n",
        "        mask = Image.fromarray((mask * 255).astype(np.uint8))\n",
        "        # transform 적용\n",
        "        if self.transform:\n",
        "            img  = self.transform(img)\n",
        "            mask = self.transform(mask)\n",
        "        return img, mask\n",
        "\n",
        "\n",
        "# 5) Transform & DataLoader\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_ds = SteelDataset(df, IMG_FOLDER, transform=data_transforms)\n",
        "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=2, pin_memory=True)\n",
        "\n",
        "# 샘플 확인\n",
        "imgs, masks = next(iter(train_loader))\n",
        "print(\"배치 이미지 크기:\", imgs.shape, \"마스크 크기:\", masks.shape)\n",
        "utils.make_grid(imgs, nrow=4).permute(1,2,0)\n",
        "\n",
        "\n",
        "# 6) U-Net with ResNet-18 백본 정의\n",
        "def convrelu(in_ch, out_ch, kernel, padding):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_ch, out_ch, kernel_size=kernel, padding=padding),\n",
        "        nn.ReLU(inplace=True),\n",
        "    )\n",
        "\n",
        "class UNetResNet18(nn.Module):\n",
        "    def __init__(self, n_class=1):\n",
        "        super().__init__()\n",
        "        # pretrained ResNet-18\n",
        "        backbone = models.resnet18(pretrained=True)\n",
        "        layers   = list(backbone.children())\n",
        "        # encoder\n",
        "        self.layer0 = nn.Sequential(*layers[:3])   # conv1, bn1, relu\n",
        "        self.layer1 = nn.Sequential(layers[3], layers[4])  # maxpool, layer1\n",
        "        self.layer2 = layers[5]  # layer2\n",
        "        self.layer3 = layers[6]  # layer3\n",
        "        self.layer4 = layers[7]  # layer4\n",
        "        # 1×1 conv for skip\n",
        "        self.l4_1x1 = convrelu(512, 512, 1, 0)\n",
        "        self.l3_1x1 = convrelu(256, 256, 1, 0)\n",
        "        self.l2_1x1 = convrelu(128, 128, 1, 0)\n",
        "        self.l1_1x1 = convrelu(64,  64,  1, 0)\n",
        "        self.l0_1x1 = convrelu(64,  64,  1, 0)\n",
        "        # upsample + conv\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        self.up3 = convrelu(512+256, 256, 3, 1)\n",
        "        self.up2 = convrelu(256+128, 128, 3, 1)\n",
        "        self.up1 = convrelu(128+64,  64,  3, 1)\n",
        "        self.up0 = convrelu(64+64,   64,  3, 1)\n",
        "        # original skip\n",
        "        self.orig0 = convrelu(3,   64, 3, 1)\n",
        "        self.orig1 = convrelu(64, 64, 3, 1)\n",
        "        self.orig2 = convrelu(64+64, 64, 3, 1)\n",
        "        # final\n",
        "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x0 = self.orig0(x); x0 = self.orig1(x0)\n",
        "        l0 = self.layer0(x)\n",
        "        l1 = self.layer1(l0)\n",
        "        l2 = self.layer2(l1)\n",
        "        l3 = self.layer3(l2)\n",
        "        l4 = self.layer4(l3)\n",
        "        # decoder\n",
        "        d4 = self.l4_1x1(l4)\n",
        "        d4 = self.upsample(d4)\n",
        "        l3s = self.l3_1x1(l3)\n",
        "        d3 = self.up3(torch.cat([d4, l3s], dim=1))\n",
        "        d3 = self.upsample(d3)\n",
        "        l2s = self.l2_1x1(l2)\n",
        "        d2 = self.up2(torch.cat([d3, l2s], dim=1))\n",
        "        d2 = self.upsample(d2)\n",
        "        l1s = self.l1_1x1(l1)\n",
        "        d1 = self.up1(torch.cat([d2, l1s], dim=1))\n",
        "        d1 = self.upsample(d1)\n",
        "        l0s = self.l0_1x1(l0)\n",
        "        d0 = self.up0(torch.cat([d1, l0s], dim=1))\n",
        "        d0 = self.upsample(d0)\n",
        "        cat = torch.cat([d0, x0], dim=1)\n",
        "        cat = self.orig2(cat)\n",
        "        return self.conv_last(cat)\n",
        "\n",
        "# 7) 모델/손실/옵티마이저/스케줄러/얼리스토핑 설정\n",
        "\n",
        "import torch.optim.lr_scheduler as sched\n",
        "\n",
        "device    = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model     = UNetResNet18(n_class=1).to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3,\n",
        "                            momentum=0.9, weight_decay=1e-4)\n",
        "\n",
        "# ReduceLROnPlateau: 검증(or학습) 손실이 개선되지 않으면 LR *= factor\n",
        "scheduler    = sched.ReduceLROnPlateau(optimizer,\n",
        "                                      mode='min',\n",
        "                                      factor=0.5,\n",
        "                                      patience=3,\n",
        "                                      verbose=True)\n",
        "\n",
        "best_loss    = float('inf')\n",
        "patience_cnt = 0\n",
        "max_patience = 5\n",
        "max_epochs   = 50   # 최대 에포치 수\n",
        "\n",
        "\n",
        "# 8) 학습 루프 (스케줄러, 얼리스토핑 포함)\n",
        "\n",
        "start_time = time.time()\n",
        "for epoch in range(1, max_epochs+1):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for imgs, masks in train_loader:\n",
        "        imgs, masks = imgs.to(device), masks.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(imgs)\n",
        "        loss  = criterion(preds, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    avg_loss = train_loss / len(train_loader)\n",
        "    print(f\"[Epoch {epoch:02d}/{max_epochs}] Train Loss: {avg_loss:.6f}\")\n",
        "\n",
        "    # 1) 스케줄러 단계 (손실 기준)\n",
        "    scheduler.step(avg_loss)\n",
        "\n",
        "    # 2) EarlyStopping 체크\n",
        "    if avg_loss < best_loss:\n",
        "        best_loss    = avg_loss\n",
        "        patience_cnt = 0\n",
        "        torch.save(model.state_dict(), \"best_unet.pth\")\n",
        "\n",
        "    else:\n",
        "        patience_cnt += 1\n",
        "        print(f\"  → 개선 없음. Patience {patience_cnt}/{max_patience}\")\n",
        "        if patience_cnt >= max_patience:\n",
        "            print(\" Early stopping\")\n",
        "            break\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "print(f\"\\n총 학습 시간: {total_time:.2f}초\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "o1jnfVne9Ji2",
        "outputId": "ceddc71f-15de-4cc1-c0e1-0b4293cb6b73"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "총 샘플 수: 2103\n",
            "배치 이미지 크기: torch.Size([4, 3, 256, 256]) 마스크 크기: torch.Size([4, 1, 256, 256])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-79-2301144943.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}